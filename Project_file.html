<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Jason Houle" />

<meta name="date" content="2016-01-24" />

<title>Practical Machine Learning: Course Project Edited</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link href="data:text/css;charset=utf-8,body%7Bbackground%2Dcolor%3A%23fff%3Bmargin%3A1em%20auto%3Bmax%2Dwidth%3A700px%3Boverflow%3Avisible%3Bpadding%2Dleft%3A2em%3Bpadding%2Dright%3A2em%3Bfont%2Dfamily%3A%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3Bfont%2Dsize%3A14px%3Bline%2Dheight%3A1%2E35%7D%23header%7Btext%2Dalign%3Acenter%7D%23TOC%7Bclear%3Aboth%3Bmargin%3A0%200%2010px%2010px%3Bpadding%3A4px%3Bwidth%3A400px%3Bborder%3A1px%20solid%20%23CCCCCC%3Bborder%2Dradius%3A5px%3Bbackground%2Dcolor%3A%23f6f6f6%3Bfont%2Dsize%3A13px%3Bline%2Dheight%3A1%2E3%7D%23TOC%20%2Etoctitle%7Bfont%2Dweight%3Abold%3Bfont%2Dsize%3A15px%3Bmargin%2Dleft%3A5px%7D%23TOC%20ul%7Bpadding%2Dleft%3A40px%3Bmargin%2Dleft%3A%2D1%2E5em%3Bmargin%2Dtop%3A5px%3Bmargin%2Dbottom%3A5px%7D%23TOC%20ul%20ul%7Bmargin%2Dleft%3A%2D2em%7D%23TOC%20li%7Bline%2Dheight%3A16px%7Dtable%7Bmargin%3A1em%20auto%3Bborder%2Dwidth%3A1px%3Bborder%2Dcolor%3A%23DDDDDD%3Bborder%2Dstyle%3Aoutset%3Bborder%2Dcollapse%3Acollapse%7Dtable%20th%7Bborder%2Dwidth%3A2px%3Bpadding%3A5px%3Bborder%2Dstyle%3Ainset%7Dtable%20td%7Bborder%2Dwidth%3A1px%3Bborder%2Dstyle%3Ainset%3Bline%2Dheight%3A18px%3Bpadding%3A5px%205px%7Dtable%2C%20table%20th%2C%20table%20td%7Bborder%2Dleft%2Dstyle%3Anone%3Bborder%2Dright%2Dstyle%3Anone%7Dtable%20thead%2C%20table%20tr%2Eeven%7Bbackground%2Dcolor%3A%23f7f7f7%7Dp%7Bmargin%3A0%2E5em%200%7Dblockquote%7Bbackground%2Dcolor%3A%23f6f6f6%3Bpadding%3A0%2E25em%200%2E75em%7Dhr%7Bborder%2Dstyle%3Asolid%3Bborder%3Anone%3Bborder%2Dtop%3A1px%20solid%20%23777%3Bmargin%3A28px%200%7Ddl%7Bmargin%2Dleft%3A0%7Ddl%20dd%7Bmargin%2Dbottom%3A13px%3Bmargin%2Dleft%3A13px%7Ddl%20dt%7Bfont%2Dweight%3Abold%7Dul%7Bmargin%2Dtop%3A0%7Dul%20li%7Blist%2Dstyle%3Acircle%20outside%7Dul%20ul%7Bmargin%2Dbottom%3A0%7Dpre%2C%20code%7Bbackground%2Dcolor%3A%23f7f7f7%3Bborder%2Dradius%3A3px%3Bcolor%3A%23333%7Dpre%7Bwhite%2Dspace%3Apre%2Dwrap%3Bborder%2Dradius%3A3px%3Bmargin%3A5px%200px%2010px%200px%3Bpadding%3A10px%7Dpre%3Anot%28%5Bclass%5D%29%7Bbackground%2Dcolor%3A%23f7f7f7%7Dcode%7Bfont%2Dfamily%3AConsolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3Bfont%2Dsize%3A85%25%7Dp%20%3E%20code%2C%20li%20%3E%20code%7Bpadding%3A2px%200px%7Ddiv%2Efigure%7Btext%2Dalign%3Acenter%7Dimg%7Bbackground%2Dcolor%3A%23FFFFFF%3Bpadding%3A2px%3Bborder%3A1px%20solid%20%23DDDDDD%3Bborder%2Dradius%3A3px%3Bborder%3A1px%20solid%20%23CCCCCC%3Bmargin%3A0%205px%7Dh1%7Bmargin%2Dtop%3A0%3Bfont%2Dsize%3A35px%3Bline%2Dheight%3A40px%7Dh2%7Bborder%2Dbottom%3A4px%20solid%20%23f7f7f7%3Bpadding%2Dtop%3A10px%3Bpadding%2Dbottom%3A2px%3Bfont%2Dsize%3A145%25%7Dh3%7Bborder%2Dbottom%3A2px%20solid%20%23f7f7f7%3Bpadding%2Dtop%3A10px%3Bfont%2Dsize%3A120%25%7Dh4%7Bborder%2Dbottom%3A1px%20solid%20%23f7f7f7%3Bmargin%2Dleft%3A8px%3Bfont%2Dsize%3A105%25%7Dh5%2C%20h6%7Bborder%2Dbottom%3A1px%20solid%20%23ccc%3Bfont%2Dsize%3A105%25%7Da%7Bcolor%3A%230033dd%3Btext%2Ddecoration%3Anone%7Da%3Ahover%7Bcolor%3A%236666ff%7Da%3Avisited%7Bcolor%3A%23800080%7Da%3Avisited%3Ahover%7Bcolor%3A%23BB00BB%7Da%5Bhref%5E%3D%22http%3A%22%5D%7Btext%2Ddecoration%3Aunderline%7Da%5Bhref%5E%3D%22https%3A%22%5D%7Btext%2Ddecoration%3Aunderline%7Dcode%20%3E%20span%2Ekw%7Bcolor%3A%23555%3Bfont%2Dweight%3Abold%7Dcode%20%3E%20span%2Edt%7Bcolor%3A%23902000%7Dcode%20%3E%20span%2Edv%7Bcolor%3A%2340a070%7Dcode%20%3E%20span%2Ebn%7Bcolor%3A%23d14%7Dcode%20%3E%20span%2Efl%7Bcolor%3A%23d14%7Dcode%20%3E%20span%2Ech%7Bcolor%3A%23d14%7Dcode%20%3E%20span%2Est%7Bcolor%3A%23d14%7Dcode%20%3E%20span%2Eco%7Bcolor%3A%23888888%3Bfont%2Dstyle%3Aitalic%7Dcode%20%3E%20span%2Eot%7Bcolor%3A%23007020%7Dcode%20%3E%20span%2Eal%7Bcolor%3A%23ff0000%3Bfont%2Dweight%3Abold%7Dcode%20%3E%20span%2Efu%7Bcolor%3A%23900%3Bfont%2Dweight%3Abold%7Dcode%20%3E%20span%2Eer%7Bcolor%3A%23a61717%3Bbackground%2Dcolor%3A%23e3d2d2%7D" rel="stylesheet" type="text/css" />

</head>

<body>



<div id="header">
<h1 class="title">Practical Machine Learning: Course Project</h1>
<h4 class="author"><em>Jason Houle</em></h4>
<h4 class="date"><em>2016-01-24</em></h4>
</div>


<div id="objective" class="section level2">
<h2>Objective</h2>
<p>The goal is to create a model that can predict the manner (“classe”, or a classification of exercise technique) in which participants exercise (dumbell lift) using data points available.</p>
<p>Training data exists from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.</p>
<p>This report describes:</p>
<ul>
<li>How I built the model,</li>
<li>How I used cross validation,</li>
<li>What the expected out of sample error is,</li>
<li>Why I made the choices I did.</li>
</ul>
</div>
<div id="source-data" class="section level2">
<h2>Source Data</h2>
<p>More information about the data is available from the website here: <a href="http://groupware.les.inf.puc-rio.br/har" class="uri">http://groupware.les.inf.puc-rio.br/har</a>. Many thanks to the group that provided this data.</p>
</div>
<div id="data-processing" class="section level2">
<h2>Data Processing</h2>
<p>Training data (<a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv">training set</a> and <a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv">test set</a> in .csv files) is downloaded into a local <code>./data</code> folder. Once the data is loaded, I reviewed the <code>full_testing</code> file and stripped all columns with <code>NA</code> observations. Since these are not available for predicting the quiz cases, I decided not to use them in building my model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load</span>
full_training &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;./data/train.csv&quot;</span>)
full_testing &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;./data/test.csv&quot;</span>)

<span class="co"># Preprocessing: Use only those variables available to predict on!</span>
final_test_set &lt;-<span class="st"> </span>full_testing[,!<span class="kw">is.na</span>(full_testing[<span class="dv">1</span>,])]
train_set &lt;-<span class="st"> </span>full_training[,!<span class="kw">is.na</span>(full_testing[<span class="dv">1</span>,])]</code></pre></div>
<p>I used a 75/25 split for a cross-validation set that would allow me to estimate out-of-sample error. (Note that <code>final_test_set</code> are the 20 quiz results, while <code>testing</code> is cross-validation data.) I also carried out further preprocessing to change data types in several columns from integers to numerics.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(caret)
<span class="co"># Split 75% to train, remainder to test</span>
inTrain &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dt">y=</span>train_set$classe,
                               <span class="dt">p=</span><span class="fl">0.75</span>, <span class="dt">list=</span><span class="ot">FALSE</span>)
training &lt;-<span class="st"> </span>train_set[inTrain,]
testing &lt;-<span class="st"> </span>train_set[-inTrain,]

<span class="co"># Convert integers to numerics</span>
xx &lt;-<span class="st"> </span><span class="kw">sapply</span>(training[<span class="dv">1</span>,],class)==<span class="st">&quot;integer&quot;</span>
training[,<span class="kw">names</span>(xx[xx==<span class="ot">TRUE</span>])] &lt;-<span class="st"> </span><span class="kw">sapply</span>(training[,<span class="kw">names</span>(xx[xx==<span class="ot">TRUE</span>])],as.numeric)</code></pre></div>
</div>
<div id="data-exploration" class="section level2">
<h2>Data Exploration</h2>
<p>Initial investigation sought to establish the level to which data were correlated. (Note that <code>-c(1:7,60)</code> is used regularly from here to strip descriptor data like index, <code>user_name</code>, timestamps, etc., as well as the <code>classe</code> variable.)</p>
<p>The length of the resulting list, as well as the high degree of correlation (illustrated below with an example plot of two variables from the list) indicates that pre-processing to reduce dimensionality may be beneficial.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Calculate correlation matrix and summarize main correlated values</span>
M &lt;-<span class="st"> </span><span class="kw">abs</span>(<span class="kw">cor</span>(training[,-<span class="kw">c</span>(<span class="dv">1</span>:<span class="dv">7</span>,<span class="dv">60</span>)]))
<span class="kw">diag</span>(M) &lt;-<span class="st"> </span><span class="dv">0</span>
<span class="kw">which</span>(M &gt;<span class="st"> </span><span class="fl">0.8</span>,<span class="dt">arr.ind=</span>T)</code></pre></div>
<pre><code>##                  row col
## yaw_belt           3   1
## total_accel_belt   4   1
## accel_belt_y       9   1
## accel_belt_z      10   1
## accel_belt_x       8   2
## magnet_belt_x     11   2
## roll_belt          1   3
## roll_belt          1   4
## accel_belt_y       9   4
## accel_belt_z      10   4
## pitch_belt         2   8
## magnet_belt_x     11   8
## roll_belt          1   9
## total_accel_belt   4   9
## accel_belt_z      10   9
## roll_belt          1  10
## total_accel_belt   4  10
## accel_belt_y       9  10
## pitch_belt         2  11
## accel_belt_x       8  11
## gyros_arm_y       19  18
## gyros_arm_x       18  19
## magnet_arm_x      24  21
## accel_arm_x       21  24
## magnet_arm_z      26  25
## magnet_arm_y      25  26
## accel_dumbbell_x  34  28
## accel_dumbbell_z  36  29
## gyros_dumbbell_z  33  31
## gyros_forearm_z   46  31
## gyros_dumbbell_x  31  33
## gyros_forearm_z   46  33
## pitch_dumbbell    28  34
## yaw_dumbbell      29  36
## gyros_forearm_z   46  45
## gyros_dumbbell_x  31  46
## gyros_dumbbell_z  33  46
## gyros_forearm_y   45  46</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Example of correlated values</span>
<span class="kw">qplot</span>(training$accel_belt_z,training$roll_belt)</code></pre></div>
<p><img src="data:image/png;base64,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" alt /><br />
</p>
</div>
<div id="pca-pre-processing-and-model-fit" class="section level2">
<h2>PCA Pre-processing and Model Fit</h2>
<p>I conducted Principal Components Analysis pre-processing with 20 components. I selected 20</p>
<p>I then trained a random forest on these components. The random forest provides a good first choice for investigation and is an easy starting point.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">preProc &lt;-<span class="st"> </span><span class="kw">preProcess</span>(training[,-<span class="kw">c</span>(<span class="dv">1</span>:<span class="dv">7</span>,<span class="dv">60</span>)], <span class="dt">method=</span><span class="st">&quot;pca&quot;</span>, <span class="dt">pcaComp=</span><span class="dv">20</span>)
trainPC &lt;-<span class="st"> </span><span class="kw">predict</span>(preProc,training[,-<span class="kw">c</span>(<span class="dv">1</span>:<span class="dv">7</span>,<span class="dv">60</span>)])
modelFit &lt;-<span class="st"> </span><span class="kw">train</span>(training$classe ~<span class="st"> </span>.,<span class="dt">method=</span><span class="st">&quot;rf&quot;</span>,
                  <span class="dt">data=</span>trainPC)</code></pre></div>
<pre><code>## Loading required package: randomForest</code></pre>
<pre><code>## randomForest 4.6-12</code></pre>
<pre><code>## Type rfNews() to see new features/changes/bug fixes.</code></pre>
<pre><code>## 
## Attaching package: 'randomForest'</code></pre>
<pre><code>## The following object is masked from 'package:ggplot2':
## 
##     margin</code></pre>
<p>This took roughly one hour on my machine. (I also attempted to pare down the number of PCA components used to determine the tradeoff of speed and accuracy; however, with as few as 5 components, no noticeable speedup was observed.)</p>
<p>In this case, the first model tested provided good results and &gt; 96% accuracy.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">modelFit</code></pre></div>
<pre><code>## Random Forest 
## 
## 14718 samples
##    19 predictor
##     5 classes: 'A', 'B', 'C', 'D', 'E' 
## 
## No pre-processing
## Resampling: Bootstrapped (25 reps) 
## 
## Summary of sample sizes: 14718, 14718, 14718, 14718, 14718, 14718, ... 
## 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa      Accuracy SD  Kappa SD   
##    2    0.9641186  0.9546036  0.003280175  0.004132037
##   11    0.9565884  0.9450844  0.003500590  0.004428396
##   20    0.9452502  0.9307438  0.004932701  0.006259257
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was mtry = 2.</code></pre>
</div>
<div id="validation" class="section level2">
<h2>Validation</h2>
<p>The model was cross-validated against the test set separated above. The out-of-sample error rate is predicted as 99.5%. Importantly, the model also achieves high (&gt;.997) predictive power (both positive and negative) specifically for Class A, which is the correct exercise technique.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Check against test set</span>
testPC &lt;-<span class="st"> </span><span class="kw">predict</span>(preProc,testing[,-<span class="kw">c</span>(<span class="dv">1</span>:<span class="dv">7</span>,<span class="dv">60</span>)])
<span class="kw">confusionMatrix</span>(testing$classe,
                <span class="kw">predict</span>(modelFit,testPC))</code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1392    0    1    2    0
##          B    4  942    3    0    0
##          C    0    2  851    2    0
##          D    0    0    7  797    0
##          E    0    0    1    1  899
## 
## Overall Statistics
##                                         
##                Accuracy : 0.9953        
##                  95% CI : (0.993, 0.997)
##     No Information Rate : 0.2847        
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16     
##                                         
##                   Kappa : 0.9941        
##  Mcnemar's Test P-Value : NA            
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9971   0.9979   0.9861   0.9938   1.0000
## Specificity            0.9991   0.9982   0.9990   0.9983   0.9995
## Pos Pred Value         0.9978   0.9926   0.9953   0.9913   0.9978
## Neg Pred Value         0.9989   0.9995   0.9970   0.9988   1.0000
## Prevalence             0.2847   0.1925   0.1760   0.1635   0.1833
## Detection Rate         0.2838   0.1921   0.1735   0.1625   0.1833
## Detection Prevalence   0.2845   0.1935   0.1743   0.1639   0.1837
## Balanced Accuracy      0.9981   0.9981   0.9926   0.9960   0.9998</code></pre>
</div>
<div id="predict-final-test-values" class="section level2">
<h2>Predict Final Test Values</h2>
<p>Finally, the model was used to predict the 20 test cases that were not classfied.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Pre-process final test data using xx name set from above</span>
final_test_set[,<span class="kw">names</span>(xx[xx==<span class="ot">TRUE</span>])] &lt;-
<span class="st">    </span><span class="kw">sapply</span>(final_test_set[,<span class="kw">names</span>(xx[xx==<span class="ot">TRUE</span>])],as.numeric)

<span class="co"># Run prediction</span>
finalTestPC &lt;-<span class="st"> </span><span class="kw">predict</span>(preProc,final_test_set[,-<span class="kw">c</span>(<span class="dv">1</span>:<span class="dv">7</span>,<span class="dv">60</span>)])
predictions &lt;-<span class="st"> </span><span class="kw">predict</span>(modelFit,finalTestPC)
<span class="kw">names</span>(predictions) &lt;-<span class="st"> </span><span class="dv">1</span>:<span class="dv">20</span></code></pre></div>
<p>The model correctly predicted 19 of the 20 test cases.</p>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
